{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G$^2$Pnet: The Grassmanian Gaussian Process Network\n",
    "We check the implementation of G2PnetSolver (ver 4.) class in ../src/\n",
    "\n",
    "Created by Tianpei Xie, 04/01/2016\n",
    "\n",
    "Last Edit 04/01/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.pairwise import rbf_kernel, pairwise_kernels\n",
    "import GPy\n",
    "import GPy.util as gutil\n",
    "\n",
    "%matplotlib inline \n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ifsavefig =  False\n",
    "Ifsavedata = False\n",
    "trail = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 40\n",
    "color_map = {0:'r', 1:'c', 2:'y'}\n",
    "#center = np.zeros(2)\n",
    "#center[1] = 1\n",
    "center = None\n",
    "\n",
    "n = 40\n",
    "m = 0\n",
    "G0= nx.barbell_graph(n,m) \n",
    "#generate the bar-bell graph, which consists of two fully connected component and a path connecting them \n",
    "\n",
    "label0 = np.zeros([2*n,1])\n",
    "label0[n:2*n] = np.ones([n,1])\n",
    "#### labeling of the cluster\n",
    "for node in G0.nodes():\n",
    "    G0.node[node]['category'] = int(label0[node,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####generate the eigenspace of normalized Laplacian\n",
    "k = 3\n",
    "nnodes = nx.adjacency_matrix(G0).shape[0]\n",
    "\n",
    "ncv=max(2*k+1,int(np.sqrt(nnodes)))\n",
    "\n",
    "eigenvalues,eigenvectors= sp.sparse.linalg.eigsh(nx.laplacian_matrix(G0).asfptype(), k=k, \\\n",
    "                                                which='SM', return_eigenvectors = True, ncv=ncv)\n",
    "index=np.argsort(eigenvalues)[1:k] # 0 index is zero eigenvalue    \n",
    "pos_spectral_mat = np.real(eigenvectors[:,index]) #pos_spectral_mat is the spectral location of the nodes\n",
    "pos_spectral_df = pd.DataFrame(data=pos_spectral_mat, columns=['PX','PY'], dtype=float)\n",
    "pos_spectral_df['LABEL'] = label0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node attributes generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T= 2\n",
    "c = 2*np.pi*0.8\n",
    "data_np = np.zeros([nnodes, T])\n",
    "column_name = []\n",
    "for t in np.arange(1,T+1):\n",
    "    temp1 = np.multiply(pos_spectral_df['PX'].apply(lambda x: np.exp(-c*t*x)).values, \\\n",
    "                          pos_spectral_df['PY'].apply(lambda y: np.cos(c*t*y)).values)\n",
    "    data_np[:,t-1] = temp1\n",
    "    if t == 1:\n",
    "        column_name = str(t-1)+\"_cos\"\n",
    "    else:    \n",
    "        column_name = [column_name, str(t-1)+\"_cos\"]\n",
    "\n",
    "sigma = 0.1        \n",
    "data_np = np.add(data_np, sigma*np.random.randn(nnodes, T))    \n",
    "data_df = pd.DataFrame(data=data_np, columns=column_name, dtype=float)\n",
    "data_df['LABEL'] = label0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Ifsavedata:\n",
    "    nx.write_adjlist(G0, \"../data/04_01_2016_experiment\"+ str(trail) +\".adjlist\",delimiter=',')\n",
    "    nx.write_edgelist(G0, \"../data/04_01_2016_experiment\" + str(trail) + \".edgelist\")\n",
    "\n",
    "    np.savez(\"../data/04_01_2016_experiment\" + str(trail) + \"_data.npz\", pos_spectral_mat, data_np, label0)\n",
    "    data_df.to_csv(\"../data/04_01_2016_experiment\" + str(trail) + \"_X.csv\", index_label= 'ID')\n",
    "    pos_spectral_df.to_csv(\"../data/04_01_2016_experiment\" +  str(trail)  + \"_U.csv\", index_label= 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if Ifsavedata:\n",
    "    nx.write_adjlist(G0, \"../data/experiment_bad_03_31_2016.adjlist\",delimiter=',')\n",
    "    nx.write_edgelist(G0, \"../data/experiment_bad_03_31_2016.edgelist\")\n",
    "\n",
    "    np.savez(\"../data/experiment_bad_data_03_31_2016.npz\", pos_spectral_mat, data_np, label0)\n",
    "    data_df.to_csv(\"../data/experiment_bad_X_03_31_2016.csv\", index_label= 'ID')\n",
    "    pos_spectral_df.to_csv(\"../data/experiment_bad_U_03_31_2016.csv\", index_label= 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= data_np\n",
    "U= pos_spectral_mat\n",
    "nsample, ndim = X.shape\n",
    "_ , ndim_latent = U.shape\n",
    "\n",
    "kern = GPy.kern.RBF(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import from the G2PnetSolver_v4.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "dirorg = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, dirorg+\"/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import G2PnetSolver_v4 #G2PnetSolver_v2\n",
    "#from imp import reload\n",
    "#reload(G2PnetSolver_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from G2PnetSolver_v4 import  G2PnetSolver as Solver\n",
    "from G2PnetSolver_v4 import  Grassmann_update, check_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choice = \"near\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=150)\n",
    "\n",
    "if choice == \"random\":\n",
    "    print(\"Random Initialization\")\n",
    "    Temp = np.random.randn(nsample, nsample)\n",
    "    Temp_sym = (Temp + Temp.T) / 2 \n",
    "    _, U_temp = np.linalg.eig(Temp_sym)\n",
    "    U_test = U_temp[:, np.arange(ndim_latent)]\n",
    "    U0 = U_test\n",
    "elif choice == \"near\":\n",
    "    print(\"Initialization in neigborhood.\")\n",
    "    U0 = U\n",
    "\n",
    "eta0 = 0.75\n",
    "np.random.seed(seed=160)\n",
    "G_temp = np.random.randn(nsample, ndim_latent) / (np.sqrt(nsample * ndim_latent))\n",
    "H_temp = -np.dot((np.eye(nsample) - gutil.linalg.tdot(U0)),G_temp)\n",
    "print(str(check_step(H_temp, eta0)))\n",
    "while not check_step(H_temp, eta0):\n",
    "    np.random.seed(seed=160)\n",
    "    G_temp = np.random.randn(nsample, ndim_latent) / np.sqrt(nsample * ndim_latent)\n",
    "    H_temp = -np.dot((np.eye(nsample) - gutil.linalg.tdot(U0)),G_temp)\n",
    "U_init = Grassmann_update(U0, H_temp, eta=eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.linalg.svdvals(H_temp)*eta0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the gradient $\\frac{dL}{dU}$\n",
    "The loss function is given as negative log-likelihood of Gaussian process\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\beta, \\sigma, \\mathbf{U}) &= \\frac{pN}{2}\\log(2\\pi)+\\frac{p}{2}\\log\\det(\\mathbf{K}_{\\beta, \\sigma, \\mathbf{U}})+\\frac{1}{2}\\text{tr}\\left(\\mathbf{K}_{\\beta, \\sigma, \\mathbf{U}}^{âˆ’1}\\mathbf{X}\\mathbf{X}^T\\right) + \\frac{\\lambda}{2} \\|\\mathbf{U}\\mathbf{U}^{T} -  \\mathbf{U}_{L}\\mathbf{U}_{L}^{T}\\|_{F}^{2}\n",
    "\\end{align}\n",
    "The partial differential of $\\mathcal{L}$ with respect to $\\mathbf{K}$\n",
    "\\begin{align}\n",
    "\\mathbf{T}&= 2\\mathbf{T}_{0} - \\text{diag}\\left(\\mathbf{T}_{0}\\right),\\\\\n",
    "\\mathbf{T}_{0} &= \\frac{1}{2}\\left(\\mathbf{I} - \\mathbf{K}_{\\beta, \\sigma, \\mathbf{U}}^{-1}\\mathbf{X}\\mathbf{X}^T/p \\right)\\mathbf{K}_{\\beta, \\sigma, \\mathbf{U}}^{-1}, \\\\\n",
    "\\mathbf{K}_{r,s} &= K_{\\sigma}\\left(\\mathbf{U}_{r,:} , \\mathbf{U}_{s,:}\\right) + \\beta \\delta_{r,s}\n",
    "\\end{align}\n",
    "\n",
    "For rbf kernel, \n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathbf{K}_{\\beta, \\sigma, \\mathbf{Z}}}{\\partial \\mathbf{U}_{m,j}} \n",
    "&= -\\frac{l^{2}}{\\sigma^2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\|\\mathbf{U}_{m} -  \\mathbf{U}_{n}\\|^{2} \\right)\\left[2\\left( \\mathbf{U}_{m,i} - \\mathbf{U}_{n,j} \\right)\\right]\n",
    "\\end{align}\n",
    "\n",
    "The differential of the second norm term \n",
    "\\begin{align}\n",
    "\\frac{d}{d\\mathbf{U}}\\frac{1}{2}\\|\\mathbf{U} \\mathbf{U}^{T} -  \\mathbf{U}_{L}\\mathbf{U}_{L}^{T}\\|_{F}^{2} &=\n",
    "\\frac{d}{d\\mathbf{U}}\\frac{1}{2}\\left[\\text{tr}\\left(\\mathbf{U} \\mathbf{U}^{T}\\right) - \\text{tr}\\left(\\mathbf{U}_{L}\\mathbf{U}_{L}^{T}\\mathbf{U}\\mathbf{U}^{T}\\right)\\right]\\\\\n",
    "&= \\left(\\mathbf{I} - \\mathbf{U}_{L}\\mathbf{U}_{L}^{T}\\right)\\mathbf{U}\n",
    "\\end{align}\n",
    "\n",
    "The partial differential of $\\mathcal{L}$ with respect to $\\mathbf{U}$\n",
    "\\begin{align}\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{U}} &= \\left[\\text{tr}\\left( \\mathbf{T} \\frac{\\partial \\mathbf{K}_{\\beta, \\sigma, \\mathbf{U}}}{\\partial \\mathbf{U}_{m,j}} \\right)\\right]_{m,j} + \\lambda \\left(\\mathbf{I} - \\mathbf{U}_{L}\\mathbf{U}_{L}^{T}\\right)\\mathbf{U},\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Ifsavedata:\n",
    "    U_columns = [str(i) for i in np.arange(ndim_latent)]\n",
    "    U_df = pd.DataFrame(data = U_init, columns=U_columns, dtype= float)\n",
    "    if choice == \"random\":\n",
    "        U_df['RANDOM'] = np.ones([nsample, 1])\n",
    "    elif choice == \"near\":\n",
    "        U_df['RANDOM'] = np.zeros([nsample, 1])\n",
    "    \n",
    "    U_df.to_csv(\"../data/04_01_16_\" + str(trail)  + \"_U_init.csv\")\n",
    "    #U_df.to_csv(\"../data/U_init_bad_03_31_16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_reg = True\n",
    "lambda_array = np.array([0.01]) #10, 1, 0.001\n",
    "eta = 0.0001\n",
    "max_iters = 600\n",
    "kern_array = [GPy.kern.RBF(2) for i in np.arange(len(lambda_array))]\n",
    "kern_grass_array = [GPy.kern.RBF(2) for i in np.arange(len(lambda_array))]\n",
    "solver_array = []\n",
    "hist_nll_eu_array = []\n",
    "hist_nll_grass_array = []\n",
    "hist_Hsig_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig= plt.figure(1)\n",
    "fig.set_size_inches(12.0, 30.0)\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "for i, lambda_var in enumerate(lambda_array): \n",
    "    ax = plt.subplot(5,1,i+1)\n",
    "    solver = Solver(X=X, U=U_init, kernel=kern_array[i], U_ref= U, add_reg = add_reg, lambda_var = lambda_var, eta=eta)\n",
    "    hist_nll_eu, hist_eta, hist_kern_eu = solver.optimize(max_iters = max_iters)\n",
    "    solver_array.append(solver)\n",
    "    hist_nll_eu_array.append(hist_nll_eu)\n",
    "    \n",
    "    \n",
    "    solver2 = Solver(X=X, U=U_init, kernel=kern_grass_array[i], U_ref = U, add_reg = add_reg, lambda_var = lambda_var, eta=eta)\n",
    "    hist_nll_grass, hist_eta, hist_kern_grass = solver2.optimize(max_iters = max_iters, optimizor = \"grad_descent_grass\")\n",
    "    hist_Hsig_array.append(solver2.hist_Hsig)\n",
    "    \n",
    "    solver_array.append(solver2)\n",
    "    hist_nll_grass_array.append(hist_nll_grass)\n",
    "        \n",
    "    %xdel solver\n",
    "    %xdel solver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= plt.figure(1)\n",
    "fig.set_size_inches(12.0, 6.0*len(lambda_array))\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "for i in np.arange(len(lambda_array)):\n",
    "    ax = plt.subplot(len(lambda_array),1,i+1)\n",
    "    h1, = plt.plot(np.arange(max_iters), hist_nll_eu_array[i], 'b')\n",
    "    h2, = plt.plot(np.arange(max_iters), hist_nll_grass_array[i], 'r')\n",
    "    if add_reg:\n",
    "        ax.legend([h1, h2], [r\"Euclidean ($\\eta$ = {0:5.4f}, $\\lambda$ = {1:5.3f})\".format(eta, lambda_array[i]), \\\n",
    "                             r\"Grassmann ($\\eta$ = {0:5.4f}, $\\lambda$ = {1:5.3f})\".format(eta, lambda_array[i])], \\\n",
    "                             fontsize = 15, loc='upper center', frameon=True)\n",
    "    else:    \n",
    "        ax.legend([h1, h2], [r\"Euclidean ($\\eta$ = {0:5.4f})\".format(eta), r\"Grassmann ($\\eta$ = {0:5.4f})\".format(eta)], \\\n",
    "                             fontsize = 15, loc='upper center', frameon=True)\n",
    "    plt.grid(1)\n",
    "    plt.ylabel('negative log-likelihood', fontsize = 15)\n",
    "    plt.xlabel('iterations', fontsize = 15)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "plt.show    \n",
    "if Ifsavefig:\n",
    "    file_org = \"../figures/04_01_16_\" + str(trail) + \"_\"\n",
    "    file_tail = \"_nll_iters_Grass_Eu.eps\"\n",
    "    if choice == \"random\":\n",
    "        file_comment = \"rand\"\n",
    "    elif choice == \"near\":\n",
    "        file_comment = \"near\"\n",
    "        \n",
    "    if add_reg:\n",
    "        file_comment = file_comment +'Reg'\n",
    "        \n",
    "    fig.savefig(file_org + file_comment + file_tail )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "These plots show the comparison of learning trajectories for different regularization paramters $\\lambda$. We see that the larger $\\lambda$, the smoother the curve is. However, it introduces more biases.\n",
    "<img src=\"../figures/03_31_16_nll_iters_Grass_Eu_1_nearReg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= plt.figure(2)\n",
    "fig.set_size_inches(12.0, 6.0*len(lambda_array))\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "for i in np.arange(len(lambda_array)):\n",
    "    ax = plt.subplot(len(lambda_array),1,i+1)\n",
    "    h1, = plt.plot(np.arange(max_iters), hist_Hsig_array[i][:,0], 'b')\n",
    "    h2, = plt.plot(np.arange(max_iters), hist_Hsig_array[i][:,1], 'r')\n",
    "    if add_reg:\n",
    "        ax.legend([h1, h2], [r\"1st singular value ($\\eta$ = {0:5.4f}, $\\lambda$ = {1:5.3f})\".format(eta, lambda_array[i]), \\\n",
    "                             r\"2nd singular value ($\\eta$ = {0:5.4f}, $\\lambda$ = {1:5.3f})\".format(eta, lambda_array[i])], \\\n",
    "                             fontsize = 15, loc='upper right', frameon=True)\n",
    "    else:    \n",
    "        ax.legend([h1, h2], [r\"1st singular value ($\\eta$ = {0:5.4f})\".format(eta), r\"2nd singular value ($\\eta$ = {0:5.4f})\".format(eta)], \\\n",
    "                             fontsize = 15, loc='upper right', frameon=True)\n",
    "    plt.grid(1)\n",
    "    plt.ylabel('singular value', fontsize = 15)\n",
    "    plt.xlabel('iterations', fontsize = 15)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "plt.show    \n",
    "if Ifsavefig:\n",
    "    file_org = \"../figures/04_01_16_\" + str(trail) + \"_\"\n",
    "    file_tail = \"_sig_iters_Grass_Eu.eps\"\n",
    "    if choice == \"random\":\n",
    "        file_comment = \"rand\"\n",
    "    elif choice == \"near\":\n",
    "        file_comment = \"near\"\n",
    "        \n",
    "    if add_reg:\n",
    "        file_comment = file_comment +'Reg'\n",
    "        \n",
    "    fig.savefig(file_org + file_comment + file_tail )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ifsavefig = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
